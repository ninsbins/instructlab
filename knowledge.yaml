created_by: ninsbins
version: 3
domain: large-language-model
document_outline:
  IBM Granite is a series of decoder-only AI foundation models created by IBM.
  It was announced on September 7, 2023,[3][4] and an initial paper was
  published 4 days later.[5] Initially intended for use in the IBM's cloud-based
  data and generative AI platform Watsonx along with other models,[6] IBM opened
  the source code of some code models.[7] Granite models are trained on datasets
  curated from Internet, academic publishings, code datasets, legal and finance
  documents.[8][9][1]


  Foundation models

  A foundation model is an AI model trained on broad data at scale such that it
  can be adapted to a wide range of downstream tasks.[10]


  Granite's first foundation models were Granite.13b.instruct and
  Granite.13b.chat. The "13b" in their name comes from 13 billion, the amount of
  parameters they have as models, lesser than most of the larger models of the
  time. Later models vary from 3 to 34 billion parameters.[3][11]


  On May 6, 2024, IBM released the source code of four variations of Granite
  Code Models under Apache 2, an open source permissive license that allows
  completely free use, modification and sharing of the software, and put them on
  Hugging Face for public use.[12][13] According to IBM's own report, Granite 8b
  outperforms Llama 3 on several coding related tasks within similar range of
  parameters.[14][15]


  See also

  Mistral AI, a company that also provides open source models

  GPT

  LLaMA

  Cyc

  Gemini
seed_examples:
  - context:
      IBM Granite is a series of decoder-only AI foundation models created by
      IBM. It was announced on September 7, 2023, and an initial paper was
      published 4 days later.
    questions_and_answers:
      - question: What is IBM Granite?
        answer:
          IBM Granite is a series of decoder-only AI foundation models created
          by IBM.
      - question: When was IBM Granite announced?
        answer: September 7, 2023
      - question: What's a series of IBM decoder-only AI foundation models?
        answer: IBM Granite
  - context:
      Initially intended for use in the IBM's cloud-based data and generative
      AI platform Watsonx along with other models, IBM opened the source code
      of some code models.[7] Granite models are trained on datasets curated from
      Internet, academic publishings, code datasets, legal and finance documents.
    questions_and_answers:
      - question: What was its intended use?
        answer:
          IBM Granite was intended for use in IBM's cloud-based data and generative
          AI Platform watsonx.
      - question: What are the Granite models trained on?
        answer:
          Datasets curated from internet, academic publishings, code datasets, legal
          and finanance documents.
      - question: What is watsonx?
        answer: IBM's cloud-based data and generative AI platform
  - context:
      A foundation model is an AI model trained on broad data at scale such that
      it can be adapted to a wide range of downstream tasks.
    questions_and_answers:
      - question: What is IBM Granite?
        answer:
          IBM Granite is a series of decoder-only AI foundation models created
          by IBM.
      - question: When was IBM Granite announced?
        answer: September 7, 2023
      - question: What's a series of IBM decoder-only AI foundation models?
        answer: IBM Granite
  - context: Granite's first foundation models were Granite.13b.instruct and
      Granite.13b.chat. The "13b" in their name comes from 13 billion, the amount of
      parameters they have as models, lesser than most of the larger models of the time.
      Later models vary from 3 to 34 billion parameters.
    questions_and_answers:
      - question: What is IBM Granite?
        answer:
          IBM Granite is a series of decoder-only AI foundation models created
          by IBM.
      - question: When was IBM Granite announced?
        answer: September 7, 2023
      - question: What's a series of IBM decoder-only AI foundation models?
        answer: IBM Granite
  - context:
      On May 6, 2024, IBM released the source code of four variations of Granite Code
      Models under Apache 2, an open source permissive license that allows completely
      free use, modification and sharing of the software, and put them on Hugging Face for
      public use. According to IBM's own report, Granite 8b outperforms Llama 3
      on several coding related tasks within similar range of parameters.
    questions_and_answers:
      - question: What is IBM Granite?
        answer:
          IBM Granite is a series of decoder-only AI foundation models created
          by IBM.
      - question: When was IBM Granite announced?
        answer: September 7, 2023
      - question: What's a series of IBM decoder-only AI foundation models?
        answer: IBM Granite
document:
  repo: https://github.com/ninsbins/instructlab
  commit:
  patterns:
    -
